
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
}
h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1, h2, h3 {
    text-align: center;
}
h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
.paper-title {
    padding: 16px 0px 16px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-7 {
     width: 14.2%;
     float: left;
}
.col-6 {
     width: 16.6%;
     float: left;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.row, .author-row, .affil-row {
     overflow: auto;
}
.author-row, .affil-row {
    font-size: 20px;
}
.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 18px;
}
.affil-row {
    margin-top: 16px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: left;
    margin-top: 8px;
    margin-bottom: 8px;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 13px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
}
.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}

.supp-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 150px;
  font-weight: 600;
}

.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}
.paper-btn:hover {
    opacity: 0.85;
}
.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}
.venue {
    color: #1367a7;
}



.topnav {
  overflow: hidden;
  background-color: #EEEEEE;
}

.topnav a {
  float: left;
  color: black;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 16px;
}


.author-block {
  display: inline-block;
}

</style>


<!-- End : Google Analytics Code -->
<script type="text/javascript" src="../js/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
    <title>DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation</title>
    <meta property="og:description" content="DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6HHDEXF452"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-6HHDEXF452');
</script>

</head>


 <body>
<div class="container">
    <div class="paper-title">
      <h1>DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation</h1>
    </div>

    
    <div id="authors">
        <div class="author-row text-center">
            <span class="author-block"><a href="https://scholar.google.com/citations?user=6aYncPAAAAAJ&hl=en/">Shentong Mo</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://xieenze.github.io/">Enze Xie</a><sup>2</sup>,</span>
            <span class="author-block"><a href="http://ruihangchu.com/">Ruihang Chu</a><sup>3</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=hqDyTg8AAAAJ&hl=en/">Lewei Yao</a><sup>2</sup>,</span>
        </div>
        <div class="author-row text-center">
            <span class="author-block"><a href="https://scholar.google.com.sg/citations?user=2p7x6OUAAAAJ&hl=en/">Lanqing Hong</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=eUtEs6YAAAAJ&hl=en/">Matthias Nießner</a><sup>4</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=XboZC1AAAAAJ&hl=en/">Zhenguo Li</a><sup>2</sup></span>
        </div>

        <div class="affil-row text-center">
            <span class="author-block text-center"><sup>1</sup>MBZUAI,</span>
            <span class="author-block text-center"><sup>2</sup>Huawei Noah's Ark Lab,</span>
            <span class="author-block text-center"><sup>3</sup>CUHK,</span>
            <span class="author-block text-center"><sup>4</sup>TUM</span>
        </div>
        <!-- <div class="affil-row">
            <div class="venue text-center"><b>NeurIPS 2023</b></div>
        </div> -->

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="supp-btn" href="https://arxiv.org/abs/2307.01831">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <a class="supp-btn" href="https://github.com/DiT-3D/DiT-3D">
                <span class="material-icons"> description </span> 
                 Code (soon)
            </a>
        </div></div>
    </div>

    <section id="teaser">
            <!-- <video class="centered" width="100%" controls muted loop autoplay>
                <source src="assets/teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video> -->
            <!-- <figure style="width: 90%;">
                <a href="assets/teaser.png">
                    <img width="100%" src="assets/teaser.png">
                </a>
            </figure> -->
            <video class="centered" width="100%" muted loop autoplay>
                <source src="assets/teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
        <p class="caption">We propose DiT-3D, <strong>a novel plain Diffusion Transformer for high-fidelity and diverse 3D shape generation</strong>, which can directly operate the denoising process on voxelized point clouds.
        </p>
            <video class="centered" width="100%" muted autoplay>
            <source src="assets/framework.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
            <!-- <figure style="width: 90%;">
                <a href="assets/framework.png">
                    <img width="100%" src="assets/framework.png">
                </a>
                <p class="caption" style="margin-bottom: 1px;">
                    Our DiT-3D takes voxelized point clouds as input, and a patchification operator is used to generate token-level patch embeddings, where 3D positional embeddings are added together. Then, multiple transformer blocks based on 3D window attention extract point-voxel representations from all input tokens. Finally, the unpatchified voxel tensor output from a linear layer is devoxelized to predict the noise in the point cloud space.
                </p>
            </figure> -->
        <p class="caption" style="margin-bottom: 1px;">
            Our DiT-3D takes voxelized point clouds as input, and a patchification operator is used to generate token-level patch embeddings, where 3D positional embeddings are added together. Then, multiple transformer blocks based on 3D window attention extract point-voxel representations from all input tokens. Finally, the unpatchified voxel tensor output from a linear layer is devoxelized to predict the noise in the point cloud space.
        </p>
    </section>

    <!-- <section id="news">
        <h2>News</h2>
        <hr>
        <div class="row">
            <div><span class="material-icons"> event </span> [Dec 2021] Check out our <a href="https://github.com/NVIDIAGameWorks/kaolin/blob/master/examples/tutorial/dmtet_tutorial.ipynb">tutorial</a> that demonstrates using DMTet for 3D reconstruction! <a href="https://kaolin.readthedocs.io/en/latest/modules/kaolin.ops.conversions.html#kaolin.ops.conversions.marching_tetrahedra">Marching tetrahedra</a>, <a href="https://kaolin.readthedocs.io/en/latest/modules/kaolin.ops.mesh.html?highlight=subdivide#kaolin.ops.mesh.subdivide_tetmesh">volume subdivision</a> and <a href="https://kaolin.readthedocs.io/en/latest/modules/kaolin.ops.mesh.html?highlight=subdivision#kaolin.ops.mesh.subdivide_trianglemesh">surface subdivision</a> modules are also released in Kaolin. </div>
        </div>
    </section> -->


    <section id="abstract"/>
        <h2>Abstract</h2>
        <hr>

        <p>Recent Diffusion Transformers (e.g., DiT) have demonstrated their powerful effectiveness in generating high-quality 2D images. However, it is unclear how the Transformer architecture performs equally well in 3D shape generation, as previous 3D diffusion methods mostly adopted the U-Net architecture. 
            To bridge this gap, we propose a novel Diffusion Transformer for 3D shape generation, named DiT-3D, which can directly operate the denoising process on voxelized point clouds using plain Transformers. Compared to existing U-Net approaches, our DiT-3D is more scalable in model size and produces much higher quality generations.
            Specifically, the DiT-3D adopts the design philosophy of DiT but modifies it by incorporating 3D positional and patch embeddings to aggregate input from voxelized point clouds.
            To reduce the computational cost of self-attention in 3D shape generation, we incorporate 3D window attention into Transformer blocks, as the increased 3D token length resulting from the additional dimension of voxels can lead to high computation.
            Finally, linear and devoxelization layers are used to predict the denoised point clouds. 
            In addition, we empirically observe that the pre-trained DiT-2D checkpoint on ImageNet can significantly improve DiT-3D on ShapeNet.
            Experimental results on the ShapeNet dataset demonstrate that the proposed DiT-3D achieves state-of-the-art performance in high-fidelity and diverse 3D point cloud generation.
            </p>
    </section>

    <!-- <hr> -->
    <!-- <section id="teaser-videos">
        <div class="flex-row">
        <figure style="width: 50%;">
            <video class="centered" width="90%" controls muted loop autoplay>
                <source src="assets/mtri.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </figure>
            <div style="width: 50%;">
                <br><br>
                <p> <strong>DMTet</strong> predicts the underlying surface parameterized by an implicit function encoded via <strong>a deformable tetrahedral grid</strong>. The underlying surface is converted into an explicit mesh with a Marching Tetrahedra (MT) algorithm, which we show is differentiable. Therefore, DMTet can jointly optimize the surface geometry and topology using <strong>losses defined expliciitly on the surface mesh</strong>.</p> 

                <p>Here we demonstrate this with a 2D example, where the loss is defined as the distance between extracted surface (shown in <span style="color: red">red</span>) with ground truth point cloud (shown in <span style="color: purple">purple</span>). </p>
            </div>
        </div>
    </section> -->






    <section id="results">
        <h2>Experiments</h2>
        <hr>
        <figure style="width: 90%;">
            <a href="assets/cmp_sota.png">
                <img width="100%" src="assets/cmp_sota.png">
            </a>
            <p class="caption" style="margin-bottom: 1px;">
                We achieve the best performance in terms of all metrics, compared to previous non-DDPM and DDPM baselines.
            </p>
        </figure>
        
        <br/>
        <hr>
        <figure style="width: 70%;">
            <a href="assets/cmp_sota_vis.png">
                <img width="100%" src="assets/cmp_sota_vis.png">
            </a>
            <p class="caption" style="margin-bottom: 1px;">
                Qualitative comparisons with state-of-the-art works. The proposed DiT-3D generates high-fidelity and diverse point clouds of 3D shapes for each category.
            </p>
        </figure>

        <br/>
        <hr>
        <figure style="width: 70%;">
            <a href="assets/vis_dit3d.png">
                <img width="100%" src="assets/vis_dit3d.png">
            </a>
            <p class="caption" style="margin-bottom: 1px;">
                Qualitative visualizations of high-fidelity and diverse 3D point cloud generation.
            </p>
        </figure>


    </section>
    
    
    
    
    
    
    <section id="results">
        <h2> Experimental Analyses</h2>
        <hr>
        <figure style="width: 80%;">
            <a href="assets/ablation_study.png">
                <img width="100%" src="assets/ablation_study.png">
            </a>
            <p class="caption"> Ablation on 3D Design Components.
            </p>
        </figure>
        
        <figure style="width: 80%;">
            <a href="assets/transfer_study.png">
                <img width="100%" src="assets/transfer_study.png">
            </a>
            <p class="caption"> 
                Influence of 2D Pretrain (ImageNet) and Transferability in Domain.
            </p>
        </figure>
        <figure style="width: 80%;">
            <a href="assets/scale_study.png">
                <img width="100%" src="assets/scale_study.png">
            </a>
            <p class="caption"> 
                Scaling Patch size, Voxel size and Model Size.
            </p>
        </figure>

    </section>

    <section id="results">
        <h2> Examples of Diffusion Process </h2>
        <hr>
        <video class="centered" width="100%" muted loop autoplay>
                <source src="assets/example.mp4" type="video/mp4">
                Your browser does not support the video tag.
        </video>
        <p class="caption"> Qualitative visualizations of the diffusion process on Chair, Airplane, Car shape generation.
        </p>
        <!-- <figure style="width: 80%;">
            <a href="assets/diff_chair.png">
                <img width="100%" src="assets/diff_chair.png">
            </a>
            <a href="assets/diff_airplane.png">
                <img width="100%" src="assets/diff_airplane.png">
            </a>
            <a href="assets/diff_car.png">
                <img width="100%" src="assets/diff_car.png">
            </a>
            <p class="caption"> Qualitative visualizations of the diffusion process on Chair, Airplane, Car shape generation.
            </p>
        </figure> -->
        

    </section>
    
    



    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>
        @article{mo2023dit3d,
        title = {DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation},
        author = {Shentong Mo and Enze Xie and Ruihang Chu and Lanqing Hong and Matthias Nießner and Zhenguo Li},
        journal = {arXiv preprint arXiv: 2307.01831},
        year = {2023}
        }
        </code></pre>
    </section>

<br />
    
    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="assets/paper.pdf"><img class="screenshot" src="assets/paper_preview.png"></a>
            </div>
            <div style="width: 50%">
                <p><b>DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation</b></p>
                <p>Shentong Mo, Enze Xie, Ruihang Chu, Lanqing HONG, Matthias Nießner, Zhenguo Li</p>

                <!-- <div><span class="material-icons"> description </span><a href="assets/dmtet.pdf"> Paper camera-ready</a></div> -->
                <div><span class="material-icons"> description </span><a href="https://arxiv.org/abs/2307.01831"> arXiv version</a></div>
                <!-- <div><span class="material-icons"> description </span><a href="assets/suppl.zip"> Supplement</a></div> -->
                <!-- <div><span class="material-icons"> insert_comment </span><a href="assets/dmtet-bib.txt"> BibTeX</a></div> -->
            </div>
        </div>
    </section>

</div>
</body>
</html>
